{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59742dcb",
   "metadata": {},
   "source": [
    "# Homework 9: Moar linear models.\n",
    "\n",
    "*Instructions:*\n",
    "Please answer the following questions and submit your work\n",
    "by editing this jupyter notebook and submitting it on Canvas.\n",
    "Questions may involve math, programming, or neither,\n",
    "but you should make sure to *explain your work*:\n",
    "i.e., you should usually have a cell with at least a few sentences\n",
    "explaining what you are doing.\n",
    "\n",
    "Also, please be sure to always specify units of any quantities that have units,\n",
    "and label axes of plots (again, with units when appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fe74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "rng = np.random.default_rng(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7dc23b",
   "metadata": {},
   "source": [
    "# 1. Logistic hypotheticals\n",
    "\n",
    "Make up a situation in which you might have data like:\n",
    "$$ Y_i \\sim \\text{Binomial}\\left(1, \\frac{1}{1 + e^{-a + b X_i}} \\right) . $$\n",
    "(In other words, $Y_i = 0$ or 1 with logistic probabilities.)\n",
    "\n",
    "*(a)* Describe the situation in words, including choosing values for $a$ and $b$.\n",
    "    Make a plot of $ \\frac{1}{1 + e^{-a + b x}}$ against $x$.\n",
    "    \n",
    "*(b)* Simulate 1000 observations from this model (with values for $X$ drawn from some reasonable distribution).\n",
    "\n",
    "*(c)* Fit a logistic linear model to your simulated data.\n",
    "    Identify the estimates of $a$ and $b$ (they should be close to the real values!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af9c508",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 2. A new whale\n",
    "\n",
    "In the file [data/whales.csv](data/whales.csv)\n",
    "(direct link: [github](https://github.com/UOdsci/dsci345/raw/main/class_material/homeworks/data/whales.csv))\n",
    "are the (average) body mass (in kg) and length (in m) of 43 modern cetacean species, from [this dataset](http://esapubs.org/archive/ecol/E090/184/metadata.htm).\n",
    "Suppose that someone has found fossils of a new species of whale\n",
    "that is about 8m long,\n",
    "and they'd like to estimate how much it weighed,\n",
    "based on the length-weight relationship of modern species.\n",
    "\n",
    "*(a)* Read in the data and make a plot of mass against length.\n",
    "    Also make a plot of log(mass) against log(length).\n",
    "\n",
    "*(b)* Fit a linear model to predict log(mass) with log(length),\n",
    "    i.e., find $a$ and $b$ so that\n",
    "    $$ \\log(\\text{mass}) \\approx a + b \\log(\\text{length}) , $$\n",
    "    and add the resulting best-fit line to the plot of log(mass) against log(length).\n",
    "\n",
    "*(c)* The predicted mass of a whale of length $\\ell$ is $e^{a + b \\log(\\ell)}$.\n",
    "    Add *this* line to the original plot of mass against length.\n",
    "\n",
    "*(d)* What is the predicted weight of the 8m long whale?\n",
    "    How far off do you estimate this prediction to be?\n",
    "    (You can get the margin of error either by looking at the plot\n",
    "    or computing the standard deviations of the residuals on a log scale, and transforming.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36857b-b8a0-4a4d-8d04-a443da81aa6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 3. Find the whales\n",
    "\n",
    "Recall the [word count data](data/passages.txt) \n",
    "(direct link: [github](https://github.com/UOdsci/dsci345/raw/main/class_material/homeworks/data/passages.txt))\n",
    "that we used as an example for PCA:\n",
    "there, we constructed the array `wordmat` so that `wordmat[i,j]` contains the number of times that `words[j]` appears in passage `i`,\n",
    "using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7739b6a1-6403-4627-86d1-2e86306c5229",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "pfile = open(\"data/passages.txt\", \"r\")\n",
    "passages = pfile.read().split(\"\\n\")[:-1]\n",
    "sources = pd.read_table(\"data/passage_sources.tsv\")\n",
    "words = np.unique(\" \".join(passages).split(\" \"))[1:]\n",
    "def tabwords(x, words):\n",
    "    d = defaultdict(int)\n",
    "    for w in x.split(\" \"):\n",
    "        d[w] += 1\n",
    "    out = np.array([d[w] for w in words])\n",
    "    return out\n",
    "\n",
    "wordmat = np.array([tabwords(x, words) for x in passages])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862a27f-7d1a-467c-b19c-a9937888d8e5",
   "metadata": {},
   "source": [
    "We'll use this matrix to address the following problem:\n",
    "predict the number of times that the words \"whale\" or \"whales\" appears in a given passage,\n",
    "using occurrance counts of the other words.\n",
    "To make this a little easier, we won't use *all* words, just those that appear between 100 and 5,000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c3b495-7e80-4d78-ac43-91be35d71ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = wordmat.sum(axis=0)\n",
    "midwords = np.logical_and(np.logical_and(wordfreq > 100, wordfreq < 5000),\n",
    "                          ~np.isin(words, ['whale', 'whales']))\n",
    "has_whales = (wordmat[:,np.where(words == \"whale\")[0]] + wordmat[:,np.where(words == \"whales\")[0]]).flatten()\n",
    "wordmat = wordmat[:, midwords]\n",
    "words = words[midwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b67d03-a644-4ca9-91c4-0fe6a5cbd8dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Your goal is to use `sklearn.PoissonRegressor` to fit a Poisson GLM that predicts `has_whales` from `X`.\n",
    "To do this:\n",
    "\n",
    "*(a)* Choose 90% of the data for training and the remaining 10% for testing.\n",
    "    Write functions that fit a model with the training data,\n",
    "    and compute the standard deviation of the residuals for the testing data from a fitted model.\n",
    "    An argument to the first function should be `alpha`, which is passed on to `PoissonRegressor`.\n",
    "\n",
    "*(b)* Fit the model with the argument `alpha=0`.\n",
    "    This model should fit very poorly. Explain why.\n",
    "\n",
    "*(c)* Fit models across a range of values of `alpha`, and display the size of their residuals (on testing data) as a table or plot.\n",
    "    What is a good value for `alpha`?\n",
    "\n",
    "*(d)* Describe the best-fitting value of `alpha` from (c): \n",
    "    how well does it predict,\n",
    "    which words have the largest positive and negative coefficients in the model,\n",
    "    and what does this mean? Are there any surprises?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
