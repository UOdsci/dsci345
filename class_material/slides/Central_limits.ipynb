{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202599bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Central Limit Theorem\n",
    "\n",
    "Peter Ralph\n",
    "\n",
    "https://uodsci.github.io/dsci345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bfdf0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 8)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dsci345 as dsci # for dsci.pretty() below\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9f690",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$\\renewcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\var}{\\text{var}} \\newcommand{\\cov}{\\text{cov}} \\newcommand{\\sd}{\\text{sd}}$$\n",
    "This is here so we can use `\\P` and `\\E` and `\\var` and `\\cov` and `\\sd` in LaTeX below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75b0f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimating means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b063f6a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we have lots of observations of something and want to estimate the mean\n",
    "(i.e., the mean value of the source we're getting the observations from).\n",
    "\"Obviously\", we should use the *sample mean*:\n",
    "$$ \\bar X = \\frac{1}{n} \\left( X_1 + X_2 + \\cdots + X_n \\right) . $$\n",
    "\n",
    "Let's suppose that all the $X_i$ are independent copies of some random variable,\n",
    "and that\n",
    "$$  \\E[X_i] = \\mu \\qquad \\text{and} \\qquad \\var[X_i] = \\sigma^2 .$$\n",
    "\n",
    "We'd like to infer the value of $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17994a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is this a sensible thing to do? Well,\n",
    "by linearity of $\\E[ ]$,\n",
    "$$\\begin{aligned}\n",
    "    \\E[\\bar X]\n",
    "    &=\n",
    "    \\E[ \\frac{1}{n} \\left( X_1 + \\cdots + X_n \\right) ]\n",
    "    \\\\ &=\n",
    "    \\frac{1}{n} \\left( \\E[X_1] + \\cdots + \\E[X_n] \\right)\n",
    "    \\\\ &=\n",
    "    \\frac{1}{n} \\left( \\mu + \\cdots + \\mu \\right)\n",
    "    \\\\ &=\n",
    "    \\mu .\n",
    "\\end{aligned}$$\n",
    "\n",
    "Okay, that's a good sign? But, it's nice to know how far off it would be in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ea48c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To see how far off it would tend to be, let's compute the standard deviation;\n",
    "as usual, it's easier to compute the variance (then we take the square root).\n",
    "Since the $X_i$ are independent, the variance of their sum is the sum of their variances,\n",
    "and also $\\var[a X] = a^2 \\var[X]$,\n",
    "so\n",
    "$$\\begin{aligned}\n",
    "    \\var[\\bar X]\n",
    "    &=\n",
    "    \\var[ \\frac{1}{n} \\left( X_1 + \\cdots + X_n \\right) ]\n",
    "    \\\\ &=\n",
    "    \\frac{1}{n^2} \\left( \\var[X_1] + \\cdots + \\var[X_n] \\right)\n",
    "    \\\\ &=\n",
    "    \\frac{\\sigma^2}{n} .\n",
    "\\end{aligned}$$\n",
    "\n",
    "So,\n",
    "$$ \\sd[\\bar X] = \\frac{\\sigma}{\\sqrt{n}} . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c3f53",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've learned that $\\bar X$ is an unbiased estimator of $\\mu$,\n",
    "with an error of order $\\sigma/\\sqrt{n}$.\n",
    "\n",
    "**Next:** can we say more about the error? *Yes*, amazingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646857a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Exercise:* check this, by\n",
    "(a) taking the mean of 100 random draws;\n",
    "and then (b) taking the mean of 10000 random draws;\n",
    "the second should be 10x closer to the true mean on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a57dbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aside: covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a680d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That's if the observations are *independent*;\n",
    "what if they aren't? Consider the *covariance*:\n",
    "$$ \\cov[X,Y] = \\E[(X - \\E[X])(Y -\\E[Y])] . $$\n",
    "This is a measure of \"how much do $X$ and $Y$ tend to go up and down (relative to their means) together\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e316a4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As with the variance, this is equal to\n",
    "$$  \\cov[X, Y] = \\E[XY] - \\E[X]\\E[Y]. $$\n",
    "In fact, $\\var[X] = \\cov[X,X]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8851f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two useful facts:\n",
    "\n",
    "1. *Covariance is bilinear*: \n",
    "    $$ \\cov[ a X + Y, Z ] = a \\cov[X, Y] + \\cov[Y, Z] .$$\n",
    "\n",
    "2. If $X$ and $Y$ are independent, then $\\cov[X,Y] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6d9006",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, what happens to $\\bar X$ if all $X_i$ have the same distribution, but $\\cov[X_i, X_j] = v$?\n",
    "$$\\begin{aligned}\n",
    "\\var[\\bar X]\n",
    "&=\n",
    "\\var[(X_1 + \\cdots + X_n)/n]\n",
    "\\\\ &=\n",
    "\\frac{1}{n^2}\\cov[(X_1 + \\cdots + X_n), (X_1 + \\cdots + X_n)]\n",
    "\\\\ &=\n",
    "\\frac{1}{n^2} \\sum_{ij} \\cov[X_i, X_j]\n",
    "\\\\ &=\n",
    "\\frac{1}{n^2} \\left(\n",
    "    \\sum_i \\var[X_i] + \\sum_{i \\neq j} \\cov[X_i, X_j]\n",
    "\\right)\n",
    "\\\\ &=\n",
    "\\frac{1}{n^2} \\left(\n",
    "    n \\sigma^2 + n(n-1) v\n",
    "\\right)\n",
    "\\\\ &=\n",
    "\\frac{\\sigma^2}{n} + \\left(1 - \\frac{1}{n}\\right) v .\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f1fce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The central limit theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a0eea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **central limit theorem** says that* if $\\bar X = (X_1 + \\cdot + X_n)/n$\n",
    "is the sample mean of $n$ independent random variables\n",
    "that each have mean $\\mu$ and standard deviation $\\sigma$,\n",
    "then\n",
    "$$\n",
    "    \\P\\left\\{\n",
    "        \\frac{ \\bar X - \\mu }{ \\sigma / \\sqrt{n} }\n",
    "        > \n",
    "        x\n",
    "    \\right\\}\n",
    "    \\approx\n",
    "    \\int_x^\\infty \\frac{e^{-y^2 / 2}}{\\sqrt{2 \\pi}} dy ,\n",
    "$$\n",
    "i.e., $\\bar X$ has a distribution that is approximation Normal,\n",
    "with mean $\\mu$ and standard deviation $\\sigma/\\sqrt{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c42e07",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$^*$ *note:* the approximation is better the bigger $n$ is\n",
    "and the \"less weird\" the distribution of $X_i$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d857d2ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How big, and how weird? Good question - an easy answer comes by simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed17a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding up lots of little things\n",
    "\n",
    "We've talked about the Central Limit Theorem,\n",
    "a.k.a., \"Normal approximation\" or \"Gaussian approximation\".\n",
    "Let's see how to works in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8be1e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Random walk\n",
    "\n",
    "Let's suppose we take a walk as follows:\n",
    "flip a fair coin; if heads, go one step north; if tails, go one step south.\n",
    "Let $X_k = +1$ if we go north of the $k^\\text{th}$ step, and $X_k = -1$ if we go south,\n",
    "and $S_n = X_1 + X_2 + \\cdots + X_n$ be the displacement to the north after $n$ steps.\n",
    "\n",
    "Note that\n",
    "$$ \\E[X_k] = 0 \\qquad \\text{and} \\qquad \\sd[X_k] = 1 , $$\n",
    "so\n",
    "$$ \\E[S_n] = 0 \\qquad \\text{and} \\qquad \\sd[S_n] = \\sqrt{n} . $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd022f94",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Exercise:* make up another story about what $S_n$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23db582",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's investigate. Here's one walk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808b396",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "X = rng.choice([-1, 1], size=n, replace=True)\n",
    "S = np.cumsum(X)\n",
    "plt.plot(S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f83ae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "X = rng.choice([-1, 1], size=n, replace=True)\n",
    "S = np.cumsum(X)\n",
    "plt.plot(S);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482f4d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's lots of walks, and only the distribution of $S_n$, i.e., where they end up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b5479",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def walks(n, size):\n",
    "    X = rng.choice([-1, 1], size=(size, n))\n",
    "    S = np.sum(X, axis=1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51645f",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "S = walks(n=n, size=1000)\n",
    "plt.hist(S, bins=dsci.pretty(S, 50))\n",
    "plt.title(f\"n={n}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d6392",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "for k, ax in enumerate(axes.flatten()):\n",
    "    n = 4 * (k+1)**2\n",
    "    S = walks(n=n, size=5000)\n",
    "    ax.hist(S, bins=dsci.pretty(S, 50))\n",
    "    ax.set_title(f\"n={n}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a152e36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sums of exponentials\n",
    "\n",
    "Let's say now that $X_1, X_2, \\ldots$ are independent Exponential(1) random variables.\n",
    "Their sum has mean $n$, so let's look at\n",
    " $$ S_n = X_1 + \\cdots + X_n  - n . $$\n",
    "Notice that\n",
    " $$ \\bar X - 1 = \\frac{1}{n} S_n . $$\n",
    " \n",
    "*Exercise:* Make up a story for what $S_n$ is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1860bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "X = rng.exponential(1, size=n) - 1\n",
    "S = np.cumsum(X)\n",
    "plt.plot(S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d0394",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X = rng.exponential(1, size=n) - 1\n",
    "S = np.cumsum(X)\n",
    "plt.plot(S);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efe93d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def exp_walks(n, size):\n",
    "    X = rng.exponential(1, size=(size, n))\n",
    "    S = np.sum(X, axis=1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef282499",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "for k, ax in enumerate(axes.flatten()):\n",
    "    n = 2 * (k+1)**2\n",
    "    S = exp_walks(n=n, size=5000)\n",
    "    ax.hist(S, bins=dsci.pretty(S, 50))\n",
    "    ax.set_title(f\"n={n}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61612c2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: counting bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c21b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we are estimating bike lane usage\n",
    "by counting bikes from 5-6pm every day at a particular spot.\n",
    "If we do it for 25 days,\n",
    "and the number per day has mean 120 with standard deviation 50,\n",
    "how close will our average be to 120?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d5f47",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Well, $\\bar X$ is the average number of bikes/day over $n=25$ days,\n",
    "so we know that $\\E[\\bar X] = \\mu = 120$ bikes,\n",
    "and $\\sd[\\bar X] = \\sigma / \\sqrt{n} = 50 / \\sqrt{25} = 10$ bikes...\n",
    "so, within $\\pm 20$ bikes or so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "x = 20\n",
    "2 * (1 - norm.cdf(120 + x, scale=10, loc=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f3ae2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More precisely,\n",
    "$$ \\bar X \\approx \\text{Normal}(\\text{mean}=120, \\text{sd}=10) ,$$\n",
    "so\n",
    "$$\n",
    " \\P\\left\\{\n",
    " | \\bar X - 120 | > x\n",
    " \\right\\}\n",
    " \\approx\n",
    " 2 \\int_{10x}^\\infty \\frac{e^{-y^2/2}}{\\sqrt{2 \\pi}} dy .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88cbe7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: jelly beans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60307342",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each bag of jelly beans has 100 beans in it.\n",
    "The average weight per bag is 240g,\n",
    "with and SD of 10g.\n",
    "Bags weighing less than 210g can't be sold.\n",
    "What percent of the bags are too light?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d3b84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Well, probably\n",
    "$$ W \\sim \\text{Normal}(\\text{mean}=240g, \\text{sd}=10g), $$\n",
    "so the proportion is probably close to\n",
    "$$\n",
    "    \\P\\{W < 210g\\}\n",
    "    =\n",
    "    \\P\\{ \\frac{W - 240}{10} < -3 \\}\n",
    "    \\approx\n",
    "    \\int_{-\\infty}^{-3}\n",
    "    \\frac{e^{-y^2/2}}{\\sqrt{2\\pi}}\n",
    "    dy .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(210, loc=240, scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d807bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note what we did there - to answer the question, we needed\n",
    "to know the *probability distribution* of $W$, which was not stated,\n",
    "only the mean and SD!\n",
    "So, we said that \"gee since it's the sum of a bunch of things it's probably Normal\"."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "rise": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
