{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202599bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Crossvalidation and Regularization\n",
    "\n",
    "Peter Ralph\n",
    "\n",
    "https://uodsci.github.io/dsci345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bfdf0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 8)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dsci345 import pretty\n",
    "\n",
    "rng = np.random.default_rng(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec5c59",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$\\renewcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\var}{\\text{var}} \\newcommand{\\sd}{\\text{sd}} \\newcommand{\\cov}{\\text{cov}} \\newcommand{\\cor}{\\text{cor}}$$\n",
    "This is here so we can use `\\P` and `\\E` and `\\var` and `\\cov` and `\\cor` and `\\sd` in LaTeX below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6bfa48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A cautionary tale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38512175",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "full_covid = pd.read_csv(\"data/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv\")[[\"state\", \"tot_cases\", \"submission_date\"]]\n",
    "covid = full_covid.rename(columns={'submission_date': 'date', \"tot_cases\": \"cases\"})\n",
    "covid.date = pd.to_datetime(covid.date)\n",
    "covid = covid[covid.date < np.datetime64(\"2021-01-01\")]\n",
    "covid = covid[covid.date.dt.dayofweek == 0]\n",
    "states = ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL',\n",
    "       'GA', 'GU', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA',\n",
    "       'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND',\n",
    "       'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA',\n",
    "       'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA',\n",
    "       'VT', 'WA', 'WI', 'WV', 'WY']\n",
    "covid = covid[np.isin(covid.state, states)]\n",
    "covid = covid.pivot(index=\"date\", columns=\"state\")\n",
    "covid = covid.diff()[1:]\n",
    "covid.columns = [x[1] for x in covid.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408390e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " Here are weekly COVID case counts across the US states plus DC, PR, and GU for 2020,\n",
    " a 48 x 53 matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81101624",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188eae7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Question:** Can we predict, say, Oregon's case counts\n",
    "using the other states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as lm\n",
    "other_states = covid.loc[:,covid.columns != \"OR\"]\n",
    "obs_OR = covid.loc[:,\"OR\"]\n",
    "OR_fit = lm().fit(other_states, obs_OR)\n",
    "est_OR = OR_fit.predict(other_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(covid.index, obs_OR, label=\"observed\")\n",
    "plt.plot(covid.index, est_OR, label=\"estimated\", linestyle=\"--\")\n",
    "plt.legend(); plt.xlabel(\"date\"); plt.ylabel(\"OR case counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd16937",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Gee, we can predict the case counts *perfectly*?\n",
    "Does that seem very likely? What's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f599ead",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's think about what we're trying to do here.\n",
    "We're trying to find coefficients $b_1, \\ldots, b_k$\n",
    "so that the the linear combination of the columns of $X$\n",
    "$$  \\hat y = b_1 X_{\\cdot 1} + \\cdots + b_k X_{\\cdot k} $$\n",
    "is as close to $y$ as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d270f78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Well, when is it possible to find $b$ so that $\\hat y = y$?\n",
    "It is possible if $y$ is in the column space of $X$.\n",
    "\n",
    "Recall that $X$ is an $n \\times k$ matrix.\n",
    "If $n \\le k$ then the columns of $X$ span then *entire* space $\\mathbb{R}^n$\n",
    "(unless for instance some columns are identical)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd74bd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Takeaway:* if you have more variables than observations\n",
    "(the problem is *singular* and)\n",
    "it is always possible to *exactly* predict the response.\n",
    "\n",
    "*However,* these predictions are unlikely to be *generalizable*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db9c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b8fcf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to tell how good your model is?\n",
    "\n",
    "*See how well it predicts \"new\" data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119178a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To do $k$-fold crossvalidation:\n",
    "\n",
    "1. Split your dataset into $k$ chunks (these should be independent!), and\n",
    "2. for each chunk in turn, put it aside for \"testing\"\n",
    "    and train your model on the remaining $k-1$ chunks.\n",
    "3. Compare \"test error\" to \"training error\".\n",
    "\n",
    "Predictions for data used to fit the model (\"training error\")\n",
    "should not be much further off than for data held out (\"test error\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0844f33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This can be used either as an indication of *overfitting*\n",
    "or to compare different models to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effe8f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Crossvalidation set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d48de8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's a pretty 'easy' prediction problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "x = np.array([\n",
    "    rng.uniform(low=0, high=10, size=n),\n",
    "    rng.normal(size=n),\n",
    "]).T\n",
    "y = 2.5 + 1.5 * x[:,0] - 4.2 * x[:,1] + rng.normal(size=n)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.scatter(x[:,0], y); ax0.set_xlabel(\"x0\"); ax0.set_ylabel(\"y\")\n",
    "ax1.scatter(x[:,1], y); ax1.set_xlabel(\"x1\"); ax1.set_ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae605053",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's (a) fit a linear model\n",
    "and (b) do crossvalidation to look for evidence of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(X, y, model):\n",
    "    yhat = model.predict(X)\n",
    "    resids = y - yhat\n",
    "    return np.sqrt(np.mean(resids ** 2))\n",
    "\n",
    "def kfold(k, X, y, model):\n",
    "    n  = len(y)\n",
    "    folds = np.repeat(np.arange(k), np.ceil(n / k))[:n]\n",
    "    rng.shuffle(folds)\n",
    "    test_rmse = []\n",
    "    train_rmse = []\n",
    "    for ik in range(k):\n",
    "        test_X = X[folds == ik]\n",
    "        test_y = y[folds == ik]\n",
    "        train_X = X[folds != ik]\n",
    "        train_y = y[folds != ik]\n",
    "        model.fit(train_X, train_y)\n",
    "        test_rmse.append(rmse(test_X, test_y, model))\n",
    "        train_rmse.append(rmse(train_X, train_y, model))\n",
    "    return pd.DataFrame({\n",
    "        \"test\" : test_rmse,\n",
    "        \"train\" : train_rmse,\n",
    "    })\n",
    "\n",
    "crossval = kfold(5, x, y, lm())\n",
    "crossval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92ef41-163b-45c6-a75c-3ae4142b457e",
   "metadata": {},
   "source": [
    "*Conclusion:* test error was higher than training error,\n",
    "but not much; there is (unsurprisingly) no evidence of (serious) overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4dc05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When you've got too many variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4ca9e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We're going to *add more variables* -\n",
    "these will be *independent* of everything else, so they should *not*\n",
    "give us meaningful predictive power for $y$.\n",
    "However, by chance each is a little correlated with $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854326c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = pd.DataFrame()\n",
    "for new_vars in np.linspace(0, 80, 9):\n",
    "    new_x = rng.normal(size=(n, int(new_vars)))\n",
    "    X = np.column_stack([x, new_x])\n",
    "    xval = kfold(5, X, y, lm())\n",
    "    xval[\"new_vars\"] = int(new_vars)\n",
    "    crossval = pd.concat([crossval, xval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval.groupby(\"new_vars\").agg(np.mean).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b56d9b-0180-49c0-ae07-e03677d05d69",
   "metadata": {},
   "source": [
    "*Conclusion:* as the number of variables increases, the training error decreases - even though we *know* there's no new information being added!\n",
    "The model is overfitting, which leads to increasing test (i.e., out-of-sample) error - the thing we generally care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6bdde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fabd2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall that, somewhat mysteriously,\n",
    "scikit-learn's method to fit a Binomial GLM with a logistic link function\n",
    "[has a \"penalty\" option](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "What's that?\n",
    "\n",
    "Well, method finds $b$ to maximize the likelihood under the following model:\n",
    "$$ Y_i \\sim \\text{Binomial}(N, p(X_i \\cdot b)), $$\n",
    "where $p(\\cdot)$ is the logistic function.\n",
    "The terms in the log-likelihood that depend on $b$ are\n",
    "$$\n",
    "    \\sum_{i=1}^n \\left\\{\n",
    "        Y_i \\log(p(X_i \\cdot b)) + (N_i - Y_i) \\log(1 - p(X_i \\cdot b))\n",
    "    \\right\\} .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4713898f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The problem we had above\n",
    "was that the variables that didn't matter\n",
    "had small but nonzero estimated parameters;\n",
    "and there were so many of them,\n",
    "that together they added up to something big.\n",
    "\n",
    "*Solution:* \"encourage\" them to be small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658c015",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, with a \"penalty\" the method instead maximizes the log-likelihood **minus**\n",
    "a \"regularization\" term that does the \"encouraging\".\n",
    "Options:\n",
    "$$\\begin{aligned}\n",
    "  \\sum_j |b_j| \\qquad & \\text{\"L1\" or \"$\\ell_1$\" or \"lasso\"}\\\\\n",
    "  \\sum_j b_j^2 \\qquad & \\text{\"L2\" or \"$\\ell_2$\" or \"ridge\" or \"Tikhonov\"}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b08b74-8d23-43e3-b658-57d307ba6988",
   "metadata": {},
   "source": [
    "```\n",
    "sklearn.linear_model.LogisticRegression(penalty=\"l1\")\n",
    "```\n",
    "therefore finds the $b$ that maximizes\n",
    "$$\n",
    "    \\sum_{i=1}^n \\left\\{\n",
    "        Y_i \\log(p(X_i \\cdot b)) + (N_i - Y_i) \\log(1 - p(X_i \\cdot b))\n",
    "    \\right\\} . - \\sum_j |b_j| .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a88a5a-0b4a-47ea-9fe4-fccf16c738f4",
   "metadata": {},
   "source": [
    "# The Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebdf5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out this scheme on our example data, using [the Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html),\n",
    "which fits a standard least-squares linear model but with a L1 penalty, minimizing\n",
    "$$ \\sum_i (y_i - X_i \\cdot b)^2 + \\alpha \\sum_j |b_j| . $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa99130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "ridge_crossval = pd.DataFrame()\n",
    "for new_vars in np.linspace(0, 80, 9):\n",
    "    new_x = rng.normal(size=(len(y), int(new_vars)))\n",
    "    X = np.column_stack([x, new_x])\n",
    "    xval = kfold(5, X, y, Lasso(alpha=.3))\n",
    "    xval[\"new_vars\"] = int(new_vars)\n",
    "    ridge_crossval = pd.concat([ridge_crossval, xval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aafe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_crossval.groupby(\"new_vars\").agg(np.mean).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e963c6-228e-4040-a24e-460d3d8a3e48",
   "metadata": {},
   "source": [
    "Test error is still consistently higher than training error - as we'd expect - but only slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173181f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553056e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's use *crossvalidation* to choose the *strength of regularization*\n",
    "(i.e., the $\\alpha$ parameter in the lasso).\n",
    "\n",
    "We'll apply it to the `covid` data above."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "rise": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
